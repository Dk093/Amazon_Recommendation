{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#import all the necessary packages.\n",
    "\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import math\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity  \n",
    "from sklearn.metrics import pairwise_distances\n",
    "from matplotlib import gridspec\n",
    "from scipy.sparse import hstack\n",
    "import plotly\n",
    "import plotly.figure_factory as ff\n",
    "from plotly.graph_objs import Scatter, Layout\n",
    "\n",
    "plotly.offline.init_notebook_mode(connected=True)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras import applications\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>brand</th>\n",
       "      <th>color</th>\n",
       "      <th>medium_image_url</th>\n",
       "      <th>product_type_name</th>\n",
       "      <th>title</th>\n",
       "      <th>formatted_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>110006</th>\n",
       "      <td>0000000060</td>\n",
       "      <td>Jofit</td>\n",
       "      <td>White</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>BUILDING_MATERIAL</td>\n",
       "      <td>jofit womens jo tech polo white extra large</td>\n",
       "      <td>$25.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77667</th>\n",
       "      <td>6042589113</td>\n",
       "      <td>Dress on Trend</td>\n",
       "      <td>White</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>SHIRT</td>\n",
       "      <td>dress trend womens lion chain print baggy over...</td>\n",
       "      <td>$16.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158935</th>\n",
       "      <td>6342521018</td>\n",
       "      <td>Crazy</td>\n",
       "      <td>Beige</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>SHIRT</td>\n",
       "      <td>crazy womens floral sleeveless vintage crochet...</td>\n",
       "      <td>$9.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134717</th>\n",
       "      <td>B00029I0Z6</td>\n",
       "      <td>Roper</td>\n",
       "      <td>Red 2</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>SHIRT</td>\n",
       "      <td>roper womens ls stars stripes pieced flag red ...</td>\n",
       "      <td>$48.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113017</th>\n",
       "      <td>B0006LTFTK</td>\n",
       "      <td>Ideology</td>\n",
       "      <td>Noir</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>PANTS</td>\n",
       "      <td>ideology womens graphic training leggings noir...</td>\n",
       "      <td>$49.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              asin           brand  color  \\\n",
       "110006  0000000060           Jofit  White   \n",
       "77667   6042589113  Dress on Trend  White   \n",
       "158935  6342521018           Crazy  Beige   \n",
       "134717  B00029I0Z6           Roper  Red 2   \n",
       "113017  B0006LTFTK        Ideology   Noir   \n",
       "\n",
       "                                         medium_image_url  product_type_name  \\\n",
       "110006  https://images-na.ssl-images-amazon.com/images...  BUILDING_MATERIAL   \n",
       "77667   https://images-na.ssl-images-amazon.com/images...              SHIRT   \n",
       "158935  https://images-na.ssl-images-amazon.com/images...              SHIRT   \n",
       "134717  https://images-na.ssl-images-amazon.com/images...              SHIRT   \n",
       "113017  https://images-na.ssl-images-amazon.com/images...              PANTS   \n",
       "\n",
       "                                                    title formatted_price  \n",
       "110006       jofit womens jo tech polo white extra large           $25.99  \n",
       "77667   dress trend womens lion chain print baggy over...          $16.00  \n",
       "158935  crazy womens floral sleeveless vintage crochet...           $9.99  \n",
       "134717  roper womens ls stars stripes pieced flag red ...          $48.78  \n",
       "113017  ideology womens graphic training leggings noir...          $49.50  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sorting ascending order since the image features are in ascending order\n",
    "data = pd.read_pickle('pickels/16k_apperal_data_preprocessed')\n",
    "data=data.sort_values(by='asin',ascending=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf_title_vectorizer = CountVectorizer()\n",
    "idf_title_features = idf_title_vectorizer.fit_transform(data['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "import pickle\n",
    "\n",
    "# in this project we are using a pretrained model by google\n",
    "# its 3.3G file, once you load this into your memory \n",
    "# it occupies ~9Gb, so please do this step only if you have >12G of ram\n",
    "# we will provide a pickle file wich contains a dict , \n",
    "# and it contains all our courpus words as keys and  model[word] as values\n",
    "# To use this code-snippet, download \"GoogleNews-vectors-negative300.bin\" \n",
    "# from https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit\n",
    "# it's 1.9GB in size.\n",
    "\n",
    "'''\n",
    "model = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab = stores all the words that are there in google w2v model\n",
    "# vocab = model.wv.vocab.keys() # if we are using Google word2Vec\n",
    "\n",
    "vocab = model.keys()\n",
    "# this function will add the vectors of each word and returns the avg vector of given sentance\n",
    "def build_avg_vec(sentence, num_features, doc_id, m_name):\n",
    "    # sentace: its title of the apparel\n",
    "    # num_features: the lenght of word2vec vector, its values = 300\n",
    "    # m_name: model information it will take two values\n",
    "        # if  m_name == 'avg', we will append the model[i], w2v representation of word i\n",
    "        # if m_name == 'weighted', we will multiply each w2v[word] with the idf(word)\n",
    "\n",
    "    featureVec = np.zeros((num_features,), dtype=\"float32\")\n",
    "    # we will intialize a vector of size 300 with all zeros\n",
    "    # we add each word2vec(wordi) to this fetureVec\n",
    "    nwords = 0\n",
    "    \n",
    "    for word in sentence.split():\n",
    "        nwords += 1\n",
    "        if word in vocab:\n",
    "            if m_name == 'weighted' and word in  idf_title_vectorizer.vocabulary_:\n",
    "                featureVec = np.add(featureVec, idf_title_features[doc_id, idf_title_vectorizer.vocabulary_[word]] * model[word])\n",
    "            elif m_name == 'avg':\n",
    "                featureVec = np.add(featureVec, model[word])\n",
    "    if(nwords>0):\n",
    "        featureVec = np.divide(featureVec, nwords)\n",
    "    # returns the avg vector of given sentance, its of shape (1, 300)\n",
    "    return featureVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_id = 0\n",
    "w2v_title_weight = []\n",
    "# for every title we build a weighted vector representation\n",
    "for i in data['title']:\n",
    "    w2v_title_weight.append(build_avg_vec(i, 300, doc_id,'weighted'))\n",
    "    doc_id += 1\n",
    "# w2v_title = np.array(# number of doc in courpus * 300), each row corresponds to a doc \n",
    "w2v_title_weight = np.array(w2v_title_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some of the brand values are empty. \n",
    "# Need to replace Null with string \"NULL\"\n",
    "data['brand'].fillna(value=\"Not given\", inplace=True )\n",
    "\n",
    "# replace spaces with hypen\n",
    "brands = [x.replace(\" \", \"-\") for x in data['brand'].values]\n",
    "types = [x.replace(\" \", \"-\") for x in data['product_type_name'].values]\n",
    "colors = [x.replace(\" \", \"-\") for x in data['color'].values]\n",
    "\n",
    "brand_vectorizer = CountVectorizer()\n",
    "brand_features = brand_vectorizer.fit_transform(brands)\n",
    "\n",
    "#type_vectorizer = CountVectorizer()\n",
    "#type_features = type_vectorizer.fit_transform(types)\n",
    "\n",
    "color_vectorizer = CountVectorizer()\n",
    "color_features = color_vectorizer.fit_transform(colors)\n",
    "\n",
    "extra_features = hstack((brand_features, color_features)).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Image, SVG, Math, YouTubeVideo\n",
    "bottleneck_features_train = np.load('16k_data_cnn_features.npy')\n",
    "asins = np.load('16k_data_cnn_feature_asins.npy')\n",
    "asins = list(asins)\n",
    "\n",
    "# load the original 16K dataset\n",
    "#data = pd.read_pickle('pickels/16k_apperal_data_preprocessed')\n",
    "df_asins = list(data['asin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "asin                                                        B072277HVB\n",
       "brand                                                     Foxcroft NYC\n",
       "color                                                            White\n",
       "medium_image_url     https://images-na.ssl-images-amazon.com/images...\n",
       "product_type_name                                                SHIRT\n",
       "title                foxcroft nyc womens pinpoint oxford shirt noni...\n",
       "formatted_price                                                 $47.99\n",
       "Name: 177930, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[12566]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16042, 7)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heat_map_w2v_brand(sentance1, sentance2, url, doc_id1, doc_id2, df_id1, df_id2, model):\n",
    "    \n",
    "    # sentance1 : title1, input apparel\n",
    "    # sentance2 : title2, recommended apparel\n",
    "    # url: apparel image url\n",
    "    # doc_id1: document id of input apparel\n",
    "    # doc_id2: document id of recommended apparel\n",
    "    # df_id1: index of document1 in the data frame\n",
    "    # df_id2: index of document2 in the data frame\n",
    "    # model: it can have two values, 1. avg 2. weighted\n",
    "    \n",
    "    #s1_vec = np.array(#number_of_words_title1 * 300), each row is a vector(weighted/avg) of length 300 corresponds to each word in give title\n",
    "    s1_vec = get_word_vec(sentance1, doc_id1, model)\n",
    "    #s2_vec = np.array(#number_of_words_title2 * 300), each row is a vector(weighted/avg) of length 300 corresponds to each word in give title\n",
    "    s2_vec = get_word_vec(sentance2, doc_id2, model)\n",
    "    \n",
    "    # s1_s2_dist = np.array(#number of words in title1 * #number of words in title2)\n",
    "    # s1_s2_dist[i,j] = euclidean distance between words i, j\n",
    "    s1_s2_dist = get_distance(s1_vec, s2_vec)\n",
    "   \n",
    "    data_matrix = [['Asin','Brand', 'Color', 'Product type'],\n",
    "               [data['asin'].loc[df_id1],brands[doc_id1], colors[doc_id1], types[doc_id1]], # input apparel's features\n",
    "               [data['asin'].loc[df_id2],brands[doc_id2], colors[doc_id2], types[doc_id2]]] # recommonded apparel's features\n",
    "    \n",
    "    colorscale = [[0, '#1d004d'],[.5, '#f2e5ff'],[1, '#f2e5d1']] # to color the headings of each column \n",
    "    \n",
    "    # we create a table with the data_matrix\n",
    "    table = ff.create_table(data_matrix, index=True, colorscale=colorscale)\n",
    "    # plot it with plotly\n",
    "    plotly.offline.iplot(table, filename='simple_table')\n",
    "    \n",
    "    # devide whole figure space into 25 * 1:10 grids\n",
    "    gs = gridspec.GridSpec(25, 15)\n",
    "    fig = plt.figure(figsize=(25,5))\n",
    "    \n",
    "    # in first 25*10 grids we plot heatmap\n",
    "    ax1 = plt.subplot(gs[:, :-5])\n",
    "    # ploting the heap map based on the pairwise distances\n",
    "    ax1 = sns.heatmap(np.round(s1_s2_dist,6), annot=True)\n",
    "    # set the x axis labels as recommended apparels title\n",
    "    ax1.set_xticklabels(sentance2.split())\n",
    "    # set the y axis labels as input apparels title\n",
    "    ax1.set_yticklabels(sentance1.split())\n",
    "    # set title as recommended apparels title\n",
    "    ax1.set_title(sentance2)\n",
    "\n",
    "    # in last 25 * 10:15 grids we display image\n",
    "    ax2 = plt.subplot(gs[:, 10:16])\n",
    "    # we dont display grid lins and axis labels to images\n",
    "    ax2.grid(False)\n",
    "    ax2.set_xticks([])\n",
    "    ax2.set_yticks([])\n",
    "    \n",
    "    # pass the url it display it\n",
    "    display_img(url, ax2, fig)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "\n",
    "def get_word_vec(sentence, doc_id, m_name):\n",
    "    \n",
    "    # m_name: model information it will take two values\n",
    "        # if  m_name == 'avg', we will append the model[i], w2v representation of word i\n",
    "        # if m_name == 'weighted', we will multiply each w2v[word] with the idf(word)\n",
    "    vec = []\n",
    "    for i in sentence.split():\n",
    "        if i in vocab:\n",
    "            if m_name == 'weighted' and i in  idf_title_vectorizer.vocabulary_:\n",
    "                vec.append(idf_title_features[doc_id, idf_title_vectorizer.vocabulary_[i]] * model[i])\n",
    "            elif m_name == 'avg':\n",
    "                vec.append(model[i])\n",
    "        else:\n",
    "            # if the word in our courpus is not there in the google word2vec corpus, we are just ignoring it\n",
    "            vec.append(np.zeros(shape=(300,)))\n",
    "    # we will return a numpy array of shape (#number of words in title * 300 ) 300 = len(w2v_model[word])\n",
    "    # each row represents the word2vec representation of each word (weighted/avg) in given sentance \n",
    "    return  np.array(vec)\n",
    "\n",
    "def get_distance(vec1, vec2):\n",
    "    # vec1 = np.array(#number_of_words_title1 * 300), each row is a vector of length 300 corresponds to each word in give title\n",
    "    # vec2 = np.array(#number_of_words_title2 * 300), each row is a vector of length 300 corresponds to each word in give title\n",
    "    \n",
    "    final_dist = []\n",
    "    # for each vector in vec1 we caluclate the distance(euclidean) to all vectors in vec2\n",
    "    for i in vec1:\n",
    "        dist = []\n",
    "        for j in vec2:\n",
    "            # np.linalg.norm(i-j) will result the euclidean distance between vectors i, j\n",
    "            dist.append(np.linalg.norm(i-j))\n",
    "        final_dist.append(np.array(dist))\n",
    "    # final_dist = np.array(#number of words in title1 * #number of words in title2)\n",
    "    # final_dist[i,j] = euclidean distance between vectors i, j\n",
    "    return np.array(final_dist)\n",
    "\n",
    "\n",
    "def heat_map_w2v(sentence1, sentence2, url, doc_id1, doc_id2, model):\n",
    "    # sentance1 : title1, input apparel\n",
    "    # sentance2 : title2, recommended apparel\n",
    "    # url: apparel image url\n",
    "    # doc_id1: document id of input apparel\n",
    "    # doc_id2: document id of recommended apparel\n",
    "    # model: it can have two values, 1. avg 2. weighted\n",
    "    \n",
    "    #s1_vec = np.array(#number_of_words_title1 * 300), each row is a vector(weighted/avg) of length 300 corresponds to each word in give title\n",
    "    s1_vec = get_word_vec(sentence1, doc_id1, model)\n",
    "    #s2_vec = np.array(#number_of_words_title1 * 300), each row is a vector(weighted/avg) of length 300 corresponds to each word in give title\n",
    "    s2_vec = get_word_vec(sentence2, doc_id2, model)\n",
    "\n",
    "    # s1_s2_dist = np.array(#number of words in title1 * #number of words in title2)\n",
    "    # s1_s2_dist[i,j] = euclidean distance between words i, j\n",
    "    s1_s2_dist = get_distance(s1_vec, s2_vec)\n",
    "\n",
    "    \n",
    "    \n",
    "    # devide whole figure into 2 parts 1st part displays heatmap 2nd part displays image of apparel\n",
    "    gs = gridspec.GridSpec(2, 2, width_ratios=[4,1],height_ratios=[2,1]) \n",
    "    fig = plt.figure(figsize=(15,15))\n",
    "    \n",
    "    ax = plt.subplot(gs[0])\n",
    "    # ploting the heap map based on the pairwise distances\n",
    "    ax = sns.heatmap(np.round(s1_s2_dist,4), annot=True)\n",
    "    # set the x axis labels as recommended apparels title\n",
    "    ax.set_xticklabels(sentence2.split())\n",
    "    # set the y axis labels as input apparels title\n",
    "    ax.set_yticklabels(sentence1.split())\n",
    "    # set title as recommended apparels title\n",
    "    ax.set_title(sentence2)\n",
    "    \n",
    "    ax = plt.subplot(gs[1])\n",
    "    # we remove all grids and axis labels for image\n",
    "    ax.grid(False)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    display_img(url, ax, fig)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility Functions which we will use through the rest of the notebook.\n",
    "\n",
    "\n",
    "#Display an image\n",
    "def display_img(url,ax,fig):\n",
    "    # we get the url of the apparel and download it\n",
    "    response = requests.get(url)\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "    # we will display it in notebook \n",
    "    plt.imshow(img)\n",
    "  \n",
    "#plotting code to understand the algorithm's decision.\n",
    "def plot_heatmap(keys, values, labels, url, text):\n",
    "        # keys: list of words of recommended title\n",
    "        # values: len(values) ==  len(keys), values(i) represents the occurence of the word keys(i)\n",
    "        # labels: len(labels) == len(keys), the values of labels depends on the model we are using\n",
    "                # if model == 'bag of words': labels(i) = values(i)\n",
    "                # if model == 'tfidf weighted bag of words':labels(i) = tfidf(keys(i))\n",
    "                # if model == 'idf weighted bag of words':labels(i) = idf(keys(i))\n",
    "        # url : apparel's url\n",
    "\n",
    "        # we will devide the whole figure into two parts\n",
    "        gs = gridspec.GridSpec(2, 2, width_ratios=[4,1], height_ratios=[4,1]) \n",
    "        fig = plt.figure(figsize=(25,3))\n",
    "        \n",
    "        # 1st, ploting heat map that represents the count of commonly ocurred words in title2\n",
    "        ax = plt.subplot(gs[0])\n",
    "        # it displays a cell in white color if the word is intersection(lis of words of title1 and list of words of title2), in black if not\n",
    "        ax = sns.heatmap(np.array([values]), annot=np.array([labels]))\n",
    "        ax.set_xticklabels(keys) # set that axis labels as the words of title\n",
    "        ax.set_title(text) # apparel title\n",
    "        \n",
    "        # 2nd, plotting image of the the apparel\n",
    "        ax = plt.subplot(gs[1])\n",
    "        # we don't want any grid lines for image and no labels on x-axis and y-axis\n",
    "        ax.grid(False)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        \n",
    "        # we call dispaly_img based with paramete url\n",
    "        display_img(url, ax, fig)\n",
    "        \n",
    "        # displays combine figure ( heat map and image together)\n",
    "        plt.show()\n",
    "    \n",
    "def plot_heatmap_image(doc_id, vec1, vec2, url, text, model):\n",
    "\n",
    "    # doc_id : index of the title1\n",
    "    # vec1 : input apparels's vector, it is of a dict type {word:count}\n",
    "    # vec2 : recommended apparels's vector, it is of a dict type {word:count}\n",
    "    # url : apparels image url\n",
    "    # text: title of recomonded apparel (used to keep title of image)\n",
    "    # model, it can be any of the models, \n",
    "        # 1. bag_of_words\n",
    "        # 2. tfidf\n",
    "        # 3. idf\n",
    "\n",
    "    # we find the common words in both titles, because these only words contribute to the distance between two title vec's\n",
    "    intersection = set(vec1.keys()) & set(vec2.keys()) \n",
    "\n",
    "    # we set the values of non intersecting words to zero, this is just to show the difference in heatmap\n",
    "    for i in vec2:\n",
    "        if i not in intersection:\n",
    "            vec2[i]=0\n",
    "\n",
    "    # for labeling heatmap, keys contains list of all words in title2\n",
    "    keys = list(vec2.keys())\n",
    "    #  if ith word in intersection(lis of words of title1 and list of words of title2): values(i)=count of that word in title2 else values(i)=0 \n",
    "    values = [vec2[x] for x in vec2.keys()]\n",
    "    \n",
    "    # labels: len(labels) == len(keys), the values of labels depends on the model we are using\n",
    "        # if model == 'bag of words': labels(i) = values(i)\n",
    "        # if model == 'tfidf weighted bag of words':labels(i) = tfidf(keys(i))\n",
    "        # if model == 'idf weighted bag of words':labels(i) = idf(keys(i))\n",
    "\n",
    "    if model == 'bag_of_words':\n",
    "        labels = values\n",
    "    elif model == 'tfidf':\n",
    "        labels = []\n",
    "        for x in vec2.keys():\n",
    "            # tfidf_title_vectorizer.vocabulary_ it contains all the words in the corpus\n",
    "            # tfidf_title_features[doc_id, index_of_word_in_corpus] will give the tfidf value of word in given document (doc_id)\n",
    "            if x in  tfidf_title_vectorizer.vocabulary_:\n",
    "                labels.append(tfidf_title_features[doc_id, tfidf_title_vectorizer.vocabulary_[x]])\n",
    "            else:\n",
    "                labels.append(0)\n",
    "    elif model == 'idf':\n",
    "        labels = []\n",
    "        for x in vec2.keys():\n",
    "            # idf_title_vectorizer.vocabulary_ it contains all the words in the corpus\n",
    "            # idf_title_features[doc_id, index_of_word_in_corpus] will give the idf value of word in given document (doc_id)\n",
    "            if x in  idf_title_vectorizer.vocabulary_:\n",
    "                labels.append(idf_title_features[doc_id, idf_title_vectorizer.vocabulary_[x]])\n",
    "            else:\n",
    "                labels.append(0)\n",
    "\n",
    "    plot_heatmap(keys, values, labels, url, text)\n",
    "\n",
    "\n",
    "# this function gets a list of wrods along with the frequency of each \n",
    "# word given \"text\"\n",
    "def text_to_vector(text):\n",
    "    word = re.compile(r'\\w+')\n",
    "    words = word.findall(text)\n",
    "    # words stores list of all words in given string, you can try 'words = text.split()' this will also gives same result\n",
    "    return Counter(words) # Counter counts the occurence of each word in list, it returns dict type object {word1:count}\n",
    "\n",
    "\n",
    "\n",
    "def get_result(doc_id, content_a, content_b, url, model):\n",
    "    text1 = content_a\n",
    "    text2 = content_b\n",
    "    \n",
    "    # vector1 = dict{word11:#count, word12:#count, etc.}\n",
    "    vector1 = text_to_vector(text1)\n",
    "\n",
    "    # vector1 = dict{word21:#count, word22:#count, etc.}\n",
    "    vector2 = text_to_vector(text2)\n",
    "\n",
    "    plot_heatmap_image(doc_id, vector1, vector2, url, text2, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heat_map_w2v_brand(sentance1, sentance2, url, doc_id1, doc_id2, df_id1, df_id2, model):\n",
    "    \n",
    "    # sentance1 : title1, input apparel\n",
    "    # sentance2 : title2, recommended apparel\n",
    "    # url: apparel image url\n",
    "    # doc_id1: document id of input apparel\n",
    "    # doc_id2: document id of recommended apparel\n",
    "    # df_id1: index of document1 in the data frame\n",
    "    # df_id2: index of document2 in the data frame\n",
    "    # model: it can have two values, 1. avg 2. weighted\n",
    "    \n",
    "    #s1_vec = np.array(#number_of_words_title1 * 300), each row is a vector(weighted/avg) of length 300 corresponds to each word in give title\n",
    "    s1_vec = get_word_vec(sentance1, doc_id1, model)\n",
    "    #s2_vec = np.array(#number_of_words_title2 * 300), each row is a vector(weighted/avg) of length 300 corresponds to each word in give title\n",
    "    s2_vec = get_word_vec(sentance2, doc_id2, model)\n",
    "    \n",
    "    # s1_s2_dist = np.array(#number of words in title1 * #number of words in title2)\n",
    "    # s1_s2_dist[i,j] = euclidean distance between words i, j\n",
    "    s1_s2_dist = get_distance(s1_vec, s2_vec)\n",
    "   \n",
    "    data_matrix = [['Asin','Brand', 'Color', 'Product type'],\n",
    "               [data['asin'].loc[df_id1],brands[doc_id1], colors[doc_id1], types[doc_id1]], # input apparel's features\n",
    "               [data['asin'].loc[df_id2],brands[doc_id2], colors[doc_id2], types[doc_id2]]] # recommonded apparel's features\n",
    "    \n",
    "    colorscale = [[0, '#1d004d'],[.5, '#f2e5ff'],[1, '#f2e5d1']] # to color the headings of each column \n",
    "    \n",
    "    # we create a table with the data_matrix\n",
    "    table = ff.create_table(data_matrix, index=True, colorscale=colorscale)\n",
    "    # plot it with plotly\n",
    "    plotly.offline.iplot(table, filename='simple_table')\n",
    "    \n",
    "    # devide whole figure space into 25 * 1:10 grids\n",
    "    gs = gridspec.GridSpec(25, 15)\n",
    "    fig = plt.figure(figsize=(25,5))\n",
    "    \n",
    "    # in first 25*10 grids we plot heatmap\n",
    "    ax1 = plt.subplot(gs[:, :-5])\n",
    "    # ploting the heap map based on the pairwise distances\n",
    "    ax1 = sns.heatmap(np.round(s1_s2_dist,6), annot=True)\n",
    "    # set the x axis labels as recommended apparels title\n",
    "    ax1.set_xticklabels(sentance2.split())\n",
    "    # set the y axis labels as input apparels title\n",
    "    ax1.set_yticklabels(sentance1.split())\n",
    "    # set title as recommended apparels title\n",
    "    ax1.set_title(sentance2)\n",
    "\n",
    "    # in last 25 * 10:15 grids we display image\n",
    "    ax2 = plt.subplot(gs[:, 10:16])\n",
    "    # we dont display grid lins and axis labels to images\n",
    "    ax2.grid(False)\n",
    "    ax2.set_xticks([])\n",
    "    ax2.set_yticks([])\n",
    "    \n",
    "    # pass the url it display it\n",
    "    display_img(url, ax2, fig)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
